{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room Part #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating a simple RAG pipeline with [LangChain v0.2.0](https://python.langchain.com/v0.2/docs/versions/v0_2/)\n",
        "  4. Synthetic Dataset Generation for Evaluation using the [Ragas](https://github.com/explodinggradients/ragas) framework.\n",
        "  \n",
        "\n",
        "- ü§ù Breakout Room Part #2:\n",
        "  1. Evaluating our pipeline with Ragas\n",
        "  3. Making Adjustments to our RAG Pipeline\n",
        "  4. Evaluating our Adjusted pipeline against our baseline\n",
        "  5. Testing OpenAI's Claim\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!\n",
        "\n",
        "> NOTE: Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage `GPT-3.5-Turbo` as the `critic_llm`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# ü§ù Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://blog.langchain.dev/langchain-v0-1-0/) of LangChain v0.1.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "51d9c154-af83-42b2-ce72-9656729ecb9d"
      },
      "outputs": [],
      "source": [
        "! pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvAvDNWBpjQ1",
        "outputId": "20ff8c89-11db-4071-b0a0-6b9bfc0e215f"
      },
      "outputs": [],
      "source": [
        "! pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "We'll be leveraging [QDrant](https://qdrant.tech/) again as our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `pymupdf` and its dependencies which will allow us to load PDFs using the `PyMuPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "58f04109-385b-44c7-d3cb-4547d8acaea1"
      },
      "outputs": [],
      "source": [
        "! pip install -qU qdrant-client pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "97cb739d-66b4-4476-ca04-b6257004178f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.1.0\n",
        "\n",
        "Building on what we learned last week, we'll be leveraging LangChain v0.1.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.2.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "1383c5b7-bb72-49ea-d323-fcd9eed48d60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 195,\n",
              " 'format': 'PDF 1.3',\n",
              " 'title': 'The Pmarca Blog Archives',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': 'Mac OS X 10.10 Quartz PDFContext',\n",
              " 'creationDate': \"D:20150110020418Z00'00'\",\n",
              " 'modDate': \"D:20150110020418Z00'00'\",\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "a707bbf6-6338-45fc-a75e-86d693dfe2c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1864"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a QDrant VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "####‚ùì Question #1:\n",
        "\n",
        "List out a few of the techniques that Qdrant uses that make it performant.\n",
        "\n",
        "> NOTE: Check the [documentation](https://qdrant.tech/documentation/overview/) for more information about QDrant!\n",
        "\n",
        "Answer: \n",
        "1. Efficient indexing: Qdrant uses specialized data structures and indexing techniques like Hierarchical Navigable Small World (HNSW) to enable fast approximate nearest neighbor search\n",
        "2. Optimized distance metrics: Qdrant supports efficient distance metrics like Cosine Similarity, Dot Product, and Euclidean Distance for measuring vector similarities\n",
        "3. Collection-based organization: Vectors are organized into collections, allowing for efficient management and search within specific sets of data\n",
        "4. Flexible vector representations: Qdrant supports named vectors, allowing multiple vectors with different dimensionalities and metrics within a single point, enhancing versatility and performance for complex use cases\n",
        "5. Memmap storage: As an alternative to in-memory storage, Qdrant provides memmap storage, which creates a virtual address space associated with files on disk, balancing performance and memory usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "retriever = qdrant_vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"What is a rule of thumb for selecting an industry to invest in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "6dfa1ae5-8198-49a1-b213-96b34a1a5147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='the existing order ‚Äî and make sure that those forces of change\\nhave a reasonable chance at succeeding.\\nSecond rule of thumb:\\nOnce you have picked an industry, get right to the center of it' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '002df472e220464dad092aa69d49131c', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='Third rule:\\nIn a rapidly changing Held like technology, the best place to\\nget experience when you‚Äôre starting out is in younger, high-\\ngrowth companies.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '677512d47305452990ebd1bcbb328459', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='where the great opportunities can be found.\\nApply this rule when selecting which company to go to. Go to\\nthe company where all the action is happening.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '0edbf44a65a54449910ecab47a1fc021', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='growth companies.\\n(This is not necessarily true in older and more established\\nindustries, but those aren‚Äôt the industries we‚Äôre talking about.)' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '259380c1205f4e22b2c81bd67763eda4', '_collection_name': 'PMarca Blogs'}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eRCq_OKUQbKk"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "21189f0e-4b5d-4146-8071-eb0fff4a6f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MgAa9JwBuJx"
      },
      "source": [
        "####üèóÔ∏è Activity #1:\n",
        "\n",
        "Describe the pipeline shown above in simple terms. You can include a diagram if desired.\n",
        "\n",
        "Answer:  \n",
        "The user prompt is passed in via `question` property.  \n",
        "`context` is retrieved by passing the `question` to the QDrant vector store retriever.  \n",
        "`RunnablePassthrough.assign` explicitly adds the generated context to the input dict and converts the dicts in the chain to Runnable.  \n",
        "Noticed `RunnablePassthrough()` works similarly as well.  \n",
        "The final part captures the response from `primary_qa_llm` for the given `prompt` in `response` and the context in `context`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "db9953a2-758d-4723-cd95-e980a47715d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get right to the center of it.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "24ce3524-9284-4eea-f78b-4329a615d321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know.\n",
            "[Document(page_content='ask if you can call them again if things change.\\nTrust me ‚Äî they‚Äôd much rather be saying ‚Äúyes‚Äù than ‚Äúno‚Äù ‚Äî\\nthey need all the good investments they can get.\\nSecond, consider the environment.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 15, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '1eb2d2dd2e2441fe9705a887996c9561', '_collection_name': 'PMarca Blogs'}), Document(page_content='watching carefully ‚Äî if everyone agrees right up front that\\nwhatever you are doing makes total sense, it probably isn‚Äôt a new\\nand radical enough idea to justify a new company.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 152, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'f5934ceb018647759da6943aadcdaf07', '_collection_name': 'PMarca Blogs'}), Document(page_content='Third rule:\\nIn a rapidly changing Held like technology, the best place to\\nget experience when you‚Äôre starting out is in younger, high-\\ngrowth companies.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '677512d47305452990ebd1bcbb328459', '_collection_name': 'PMarca Blogs'}), Document(page_content='necessary supply of oil, gas, music, and movies.\\nIf you‚Äôre going to enter an old industry, make sure to do it on\\nthe side of the forces of radical change that threaten to up-end', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '358384ceb6df4bb7b51d5300360d3946', '_collection_name': 'PMarca Blogs'})]\n"
          ]
        }
      ],
      "source": [
        "question = \"What did Pink Floyd have to say about how to proceed when investing in a new industry?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 4: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evaluating on every core metric today, but in order to do that - we'll need to create a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 600,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter_eval.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "####‚ùì Question #2:\n",
        "\n",
        "Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "\n",
        "Answer:\n",
        "1. Diverse chunk sizes: Using different chunk sizes (200 and 600 in this case) allows for training and evaluating models on various text lengths, making them more robust and adaptable to different input sizes.  \n",
        "2. Context preservation: The larger chunk size (600) for evaluation documents helps preserve more context within each chunk for generating synthetic ground truths  \n",
        "3. Overfitting prevention: Using different parameters for training and evaluation data helps prevent the model from overfitting to a specific chunk size or structure, making it more generalizable  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "fc8c6829-5c53-4eb1-8407-1545f5a7d023"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "624"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCrVMW9Blda"
      },
      "source": [
        "\n",
        "> NOTE: üõë Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage GPT-3.5-Turbo as the critic_llm. If you're attempting to create a lot of samples please be aware of cost, as well as rate limits. üõë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f75fdd56268a4b83a7fb7e4a3b2cce82",
            "1fb5a4b71deb406fa2f342c88b9e4e1d",
            "37ec9b5c847749439d7c155ac3b1ec68",
            "1317f4e20e1c4574a360345b427c3e8a",
            "2aa53858803d4ad39113009d86dd67fc",
            "7e1d22c19aff4c768d643c249e425d00",
            "3a498872a68049329b4d206629b9b3bf",
            "89a7c333d0b241169dc29ed998b2c9c4",
            "88c8557741734e59a6099bb5fa260f6e",
            "92ef10fab64c4f40a93da3d31b572016",
            "3b43c3f561e34d019007ac9a0125b28d",
            "05ab48866b5d49df9567ce9cbda5ee2e",
            "49c1ef316e404052a7c8528781db3f9a",
            "2dcb3e2fdf164e35a27a79cfae65933a",
            "202f4244384a4501bfc1ffa50af96a1f",
            "d93698b0506743ff98fdb998cfb7080a",
            "19acd28bfa2e4a7a83bc42faea5de770",
            "356b929fa8dc42538767c58dcce12217",
            "60a663f8736a43bcb47ac6c5f37ec597",
            "e6edc46811064de2b74a6a477c4a44b7",
            "a10a7577a99b4683a1d59a09d88f93a1",
            "444bc7dae1aa4e098b79655428599310"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "1d4904f0-9674-448a-9af3-f99da62cc8f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/s.thirunavukkarasu/code/AI-Engineering-3/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Filename and doc_id are the same for all nodes.                     \n",
            "Generating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [01:48<04:27, 29.76s/it]\n",
            "Generating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 13/20 [02:15<02:28, 21.19s/it]\n",
            "Generating:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [02:40<02:14, 22.39s/it]\n",
            "Generating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [02:53<01:37, 19.41s/it]\n",
            "Generating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18/20 [03:30<00:28, 14.09s/it]\n",
            "Generating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [03:38<00:00, 10.91s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the concept of \"un...</td>\n",
              "      <td>[that chance is immune from human intervention...</td>\n",
              "      <td>nan</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the Liking/Loving Tendency influence ...</td>\n",
              "      <td>[One very practical consequence of Liking/Lovi...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What type of employees are typically hired as ...</td>\n",
              "      <td>[of creating value. And new hires will by deXn...</td>\n",
              "      <td>New hires are typically conservative and chang...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can blogging about their point of view hel...</td>\n",
              "      <td>[looking for funding to blog ‚Äî about their sta...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can focusing on creating a large market be...</td>\n",
              "      <td>[developing a large market, as opposed to Xght...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is a key feature of Peter Hamilton's stor...</td>\n",
              "      <td>[pandemics, nuclear terrorist attacks, governm...</td>\n",
              "      <td>Peter Hamilton's storytelling style in his spa...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is intelligence considered overrated in th...</td>\n",
              "      <td>[Criteria 7rst\\nLots of people will tell you t...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of temporary subfolders in...</td>\n",
              "      <td>[you can reply to a lot of messages with ‚ÄúI‚Äôm ...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Are the anticipated career peaks of highly pro...</td>\n",
              "      <td>[These three components are conspicuously link...</td>\n",
              "      <td>nan</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Is attempting to improve your batting average ...</td>\n",
              "      <td>[becomes irrelevant to determining the success...</td>\n",
              "      <td>Yes, attempting to improve your batting averag...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What factors should be considered when making ...</td>\n",
              "      <td>[the team, not good for the burn rate, and not...</td>\n",
              "      <td>The factors that should be considered when mak...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How can one gain exposure to professionals in ...</td>\n",
              "      <td>[undergrads to do some of the work, and being ...</td>\n",
              "      <td>One can gain exposure to professionals in thei...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is the advantage of modern email clients ...</td>\n",
              "      <td>[Every once in a while, sweep through your Act...</td>\n",
              "      <td>The advantage of modern email clients is that ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are common paths for venture-backed entre...</td>\n",
              "      <td>[ence, and then go to work at a venture-backed...</td>\n",
              "      <td>If you can‚Äôt get hired by a venture-backed sta...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How do previous conclusions, loyalties, reputa...</td>\n",
              "      <td>[chains I forged in life,‚Äù he is talking about...</td>\n",
              "      <td>A quickly reached conclusion, triggered by Dou...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the significance of the concept of \"un...   \n",
              "1   How does the Liking/Loving Tendency influence ...   \n",
              "2   What type of employees are typically hired as ...   \n",
              "3   How can blogging about their point of view hel...   \n",
              "4   How can focusing on creating a large market be...   \n",
              "5   What is a key feature of Peter Hamilton's stor...   \n",
              "6   Why is intelligence considered overrated in th...   \n",
              "7   What is the purpose of temporary subfolders in...   \n",
              "8   Are the anticipated career peaks of highly pro...   \n",
              "9   Is attempting to improve your batting average ...   \n",
              "10  What factors should be considered when making ...   \n",
              "11  How can one gain exposure to professionals in ...   \n",
              "12  What is the advantage of modern email clients ...   \n",
              "13  What are common paths for venture-backed entre...   \n",
              "14  How do previous conclusions, loyalties, reputa...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [that chance is immune from human intervention...   \n",
              "1   [One very practical consequence of Liking/Lovi...   \n",
              "2   [of creating value. And new hires will by deXn...   \n",
              "3   [looking for funding to blog ‚Äî about their sta...   \n",
              "4   [developing a large market, as opposed to Xght...   \n",
              "5   [pandemics, nuclear terrorist attacks, governm...   \n",
              "6   [Criteria 7rst\\nLots of people will tell you t...   \n",
              "7   [you can reply to a lot of messages with ‚ÄúI‚Äôm ...   \n",
              "8   [These three components are conspicuously link...   \n",
              "9   [becomes irrelevant to determining the success...   \n",
              "10  [the team, not good for the burn rate, and not...   \n",
              "11  [undergrads to do some of the work, and being ...   \n",
              "12  [Every once in a while, sweep through your Act...   \n",
              "13  [ence, and then go to work at a venture-backed...   \n",
              "14  [chains I forged in life,‚Äù he is talking about...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0                                                 nan         simple   \n",
              "1   The Liking/Loving Tendency influences an indiv...         simple   \n",
              "2   New hires are typically conservative and chang...         simple   \n",
              "3   Blogging about their point of view can help an...         simple   \n",
              "4   Focusing on creating a large market can be mor...         simple   \n",
              "5   Peter Hamilton's storytelling style in his spa...         simple   \n",
              "6   Intelligence is considered overrated in the in...         simple   \n",
              "7   The purpose of temporary subfolders in email o...         simple   \n",
              "8                                                 nan         simple   \n",
              "9   Yes, attempting to improve your batting averag...         simple   \n",
              "10  The factors that should be considered when mak...  multi_context   \n",
              "11  One can gain exposure to professionals in thei...  multi_context   \n",
              "12  The advantage of modern email clients is that ...  multi_context   \n",
              "13  If you can‚Äôt get hired by a venture-backed sta...  multi_context   \n",
              "14  A quickly reached conclusion, triggered by Dou...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\") # <--- If you don't have GPT-4 access, or to reduce cost/rate limiting issues.\n",
        "#critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, 20, distributions, is_async = False)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIGT0XLz8ze"
      },
      "source": [
        "####‚ùì Question #3:\n",
        "\n",
        "`{simple: 0.5, reasoning: 0.25, multi_context: 0.25}`\n",
        "\n",
        "What exactly does this mapping refer to?\n",
        "\n",
        "> NOTE: Check out the Ragas documentation on this generation process [here](https://docs.ragas.io/en/stable/concepts/testset_generation.html).\n",
        "\n",
        "Answer:  \n",
        "This mapping specifies the evolution type of the questions to be generated and their respective proportions within the given test_size. For this mapping, for test_size=100, we expect 50 simple, 25 reasoning and 25 multi_context type questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "31efbb94-f09d-4d50-8c6e-59202aaeb5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='What is the significance of the concept of \"unwilled\" in the context of chance and human interventions?', contexts=['that chance is immune from human interventions. However, one\\nmust be careful not to read any unconsciously purposeful intent\\ninto ‚Äúinterventions‚Äù‚Ä¶ [which] are to be viewed as accidental,\\nunwilled, inadvertent, and unforseeable.\\nIndeed, chance plays several distinct roles when humans react cre-\\natively with one another and with their environment‚Ä¶\\nWe can observe chance arriving in four major forms and for four\\ndiWerent reasons. The principles involved aWect everyone.\\nHere‚Äôs where it helps to be a neurologist writing on this topic:\\nThe four kinds of chance each have a diWerent kind of motor'], ground_truth='nan', evolution_type='simple', metadata=[{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 167, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': ''}])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "test_df = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "ed137f4f-df2c-41fa-d868-802d30076ea0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the concept of \"un...</td>\n",
              "      <td>[that chance is immune from human intervention...</td>\n",
              "      <td>nan</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the Liking/Loving Tendency influence ...</td>\n",
              "      <td>[One very practical consequence of Liking/Lovi...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What type of employees are typically hired as ...</td>\n",
              "      <td>[of creating value. And new hires will by deXn...</td>\n",
              "      <td>New hires are typically conservative and chang...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can blogging about their point of view hel...</td>\n",
              "      <td>[looking for funding to blog ‚Äî about their sta...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can focusing on creating a large market be...</td>\n",
              "      <td>[developing a large market, as opposed to Xght...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is a key feature of Peter Hamilton's stor...</td>\n",
              "      <td>[pandemics, nuclear terrorist attacks, governm...</td>\n",
              "      <td>Peter Hamilton's storytelling style in his spa...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is intelligence considered overrated in th...</td>\n",
              "      <td>[Criteria 7rst\\nLots of people will tell you t...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of temporary subfolders in...</td>\n",
              "      <td>[you can reply to a lot of messages with ‚ÄúI‚Äôm ...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Are the anticipated career peaks of highly pro...</td>\n",
              "      <td>[These three components are conspicuously link...</td>\n",
              "      <td>nan</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Is attempting to improve your batting average ...</td>\n",
              "      <td>[becomes irrelevant to determining the success...</td>\n",
              "      <td>Yes, attempting to improve your batting averag...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What factors should be considered when making ...</td>\n",
              "      <td>[the team, not good for the burn rate, and not...</td>\n",
              "      <td>The factors that should be considered when mak...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How can one gain exposure to professionals in ...</td>\n",
              "      <td>[undergrads to do some of the work, and being ...</td>\n",
              "      <td>One can gain exposure to professionals in thei...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is the advantage of modern email clients ...</td>\n",
              "      <td>[Every once in a while, sweep through your Act...</td>\n",
              "      <td>The advantage of modern email clients is that ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are common paths for venture-backed entre...</td>\n",
              "      <td>[ence, and then go to work at a venture-backed...</td>\n",
              "      <td>If you can‚Äôt get hired by a venture-backed sta...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How do previous conclusions, loyalties, reputa...</td>\n",
              "      <td>[chains I forged in life,‚Äù he is talking about...</td>\n",
              "      <td>A quickly reached conclusion, triggered by Dou...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the significance of the concept of \"un...   \n",
              "1   How does the Liking/Loving Tendency influence ...   \n",
              "2   What type of employees are typically hired as ...   \n",
              "3   How can blogging about their point of view hel...   \n",
              "4   How can focusing on creating a large market be...   \n",
              "5   What is a key feature of Peter Hamilton's stor...   \n",
              "6   Why is intelligence considered overrated in th...   \n",
              "7   What is the purpose of temporary subfolders in...   \n",
              "8   Are the anticipated career peaks of highly pro...   \n",
              "9   Is attempting to improve your batting average ...   \n",
              "10  What factors should be considered when making ...   \n",
              "11  How can one gain exposure to professionals in ...   \n",
              "12  What is the advantage of modern email clients ...   \n",
              "13  What are common paths for venture-backed entre...   \n",
              "14  How do previous conclusions, loyalties, reputa...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [that chance is immune from human intervention...   \n",
              "1   [One very practical consequence of Liking/Lovi...   \n",
              "2   [of creating value. And new hires will by deXn...   \n",
              "3   [looking for funding to blog ‚Äî about their sta...   \n",
              "4   [developing a large market, as opposed to Xght...   \n",
              "5   [pandemics, nuclear terrorist attacks, governm...   \n",
              "6   [Criteria 7rst\\nLots of people will tell you t...   \n",
              "7   [you can reply to a lot of messages with ‚ÄúI‚Äôm ...   \n",
              "8   [These three components are conspicuously link...   \n",
              "9   [becomes irrelevant to determining the success...   \n",
              "10  [the team, not good for the burn rate, and not...   \n",
              "11  [undergrads to do some of the work, and being ...   \n",
              "12  [Every once in a while, sweep through your Act...   \n",
              "13  [ence, and then go to work at a venture-backed...   \n",
              "14  [chains I forged in life,‚Äù he is talking about...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0                                                 nan         simple   \n",
              "1   The Liking/Loving Tendency influences an indiv...         simple   \n",
              "2   New hires are typically conservative and chang...         simple   \n",
              "3   Blogging about their point of view can help an...         simple   \n",
              "4   Focusing on creating a large market can be mor...         simple   \n",
              "5   Peter Hamilton's storytelling style in his spa...         simple   \n",
              "6   Intelligence is considered overrated in the in...         simple   \n",
              "7   The purpose of temporary subfolders in email o...         simple   \n",
              "8                                                 nan         simple   \n",
              "9   Yes, attempting to improve your batting averag...         simple   \n",
              "10  The factors that should be considered when mak...  multi_context   \n",
              "11  One can gain exposure to professionals in thei...  multi_context   \n",
              "12  The advantage of modern email clients is that ...  multi_context   \n",
              "13  If you can‚Äôt get hired by a venture-backed sta...  multi_context   \n",
              "14  A quickly reached conclusion, triggered by Dou...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "f924b59d-eb6b-4c1a-9d18-f545c4e2c724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'What is the significance of the concept of \"unwilled\" in the context of chance and human interventions?', 'answer': 'The significance of the concept of \"unwilled\" in the context of chance and human interventions is that it emphasizes that chance events are unintentional, accidental, and not driven by human intention.', 'contexts': ['unwilled, inadvertent, and unforseeable.\\nIndeed, chance plays several distinct roles when humans react cre-\\natively with one another and with their environment‚Ä¶', 'must be careful not to read any unconsciously purposeful intent\\ninto ‚Äúinterventions‚Äù‚Ä¶ [which] are to be viewed as accidental,\\nunwilled, inadvertent, and unforseeable.', 'ably.\\nFirst, he deXnes chance as follows:\\nChance‚Ä¶ something fortuitous that happens unpredictably without\\ndiscernable human intention.\\nYup, that‚Äôs luck.', 'discernable human intention.\\nYup, that‚Äôs luck.\\nChance is unintentional, it is capricious, but we needn‚Äôt conclude\\nthat chance is immune from human interventions. However, one'], 'ground_truth': 'nan'}\n"
          ]
        }
      ],
      "source": [
        "print(response_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# ü§ù Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 1: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "32514310070a426ea247c9f1bc66b630",
            "3e7520df71de40e0af5589b6aeb95171",
            "05390d20f1b445b5b02529ee7a99f6d6",
            "3380693903474d2585638f7e3458fcd6",
            "1d43002974f24e8a8b6961cddc04ce47",
            "97abe811c89c44dcacd7e39074d22546",
            "87a3d4b2ed5f4f1ca895c6a1981eb847",
            "589c2004f5504a239615dec8671785d0",
            "25d3337c457f4c748ed8bf78f5a27fe8",
            "31064d2adec14238a609d3f9791c64f3",
            "4f482b8ce7a54c1787394fb7d90391a0"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "85fa2a99-7506-45d1-a674-ca9f55372264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 33/75 [00:25<01:08,  1.64s/it]No statements were generated from the answer.\n",
            "Evaluating:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 40/75 [00:33<00:39,  1.14s/it]No statements were generated from the answer.\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [02:22<00:00,  1.90s/it]\n"
          ]
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "e8f3cb2f-8a38-47a5-f54d-ec80eaca8448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.6635, 'answer_relevancy': 0.8130, 'context_recall': 0.4978, 'context_precision': 0.6556, 'answer_correctness': 0.5280}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "a10d6394-0ab7-48bf-96c5-acfc5992622f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the concept of \"un...</td>\n",
              "      <td>The significance of the concept of \"unwilled\" ...</td>\n",
              "      <td>[unwilled, inadvertent, and unforseeable.\\nInd...</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.983218</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.182749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the Liking/Loving Tendency influence ...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>[One very practical consequence of Liking/Lovi...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.957709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.618554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What type of employees are typically hired as ...</td>\n",
              "      <td>Ambitious director- or VP-level managers.</td>\n",
              "      <td>[number of new employees recruited and hired, ...</td>\n",
              "      <td>New hires are typically conservative and chang...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.846774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.203513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can blogging about their point of view hel...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>[esting things going on, about their point of ...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.975708</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.697192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can focusing on creating a large market be...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>[competitor, be sure to take a step back and s...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.613491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is a key feature of Peter Hamilton's stor...</td>\n",
              "      <td>Large-scale military combat</td>\n",
              "      <td>[story of an enigmatic agent for the all-power...</td>\n",
              "      <td>Peter Hamilton's storytelling style in his spa...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.836724</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.192828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is intelligence considered overrated in th...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>[Especially in this industry.\\nYou will read, ...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.609262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of temporary subfolders in...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>[the normal course of your day.\\nFourth, aside...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.673740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Are the anticipated career peaks of highly pro...</td>\n",
              "      <td>Earlier</td>\n",
              "      <td>[early, end late, and produce at above-average...</td>\n",
              "      <td>nan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.953437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Is attempting to improve your batting average ...</td>\n",
              "      <td>No, attempting to improve your batting average...</td>\n",
              "      <td>[improve one‚Äôs batting average.\\n‚Ä¢\\nIntelligen...</td>\n",
              "      <td>Yes, attempting to improve your batting averag...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.236148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What factors should be considered when making ...</td>\n",
              "      <td>Factors that should be considered when making ...</td>\n",
              "      <td>[order to execute its plan? E.g. a startup pla...</td>\n",
              "      <td>The factors that should be considered when mak...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.958568</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.635472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How can one gain exposure to professionals in ...</td>\n",
              "      <td>One can gain exposure to professionals in thei...</td>\n",
              "      <td>[get real-world working experience at companie...</td>\n",
              "      <td>One can gain exposure to professionals in thei...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834602</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.509940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is the advantage of modern email clients ...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>[inside and feel like you‚Äôve done something.\\n...</td>\n",
              "      <td>The advantage of modern email clients is that ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.183807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are common paths for venture-backed entre...</td>\n",
              "      <td>Common paths for venture-backed entrepreneurs ...</td>\n",
              "      <td>[that employs a lot of people like Google or A...</td>\n",
              "      <td>If you can‚Äôt get hired by a venture-backed sta...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.775015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How do previous conclusions, loyalties, reputa...</td>\n",
              "      <td>Previous conclusions, loyalties, reputational ...</td>\n",
              "      <td>[[T]ending to be maintained in place by the an...</td>\n",
              "      <td>A quickly reached conclusion, triggered by Dou...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.808429</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the significance of the concept of \"un...   \n",
              "1   How does the Liking/Loving Tendency influence ...   \n",
              "2   What type of employees are typically hired as ...   \n",
              "3   How can blogging about their point of view hel...   \n",
              "4   How can focusing on creating a large market be...   \n",
              "5   What is a key feature of Peter Hamilton's stor...   \n",
              "6   Why is intelligence considered overrated in th...   \n",
              "7   What is the purpose of temporary subfolders in...   \n",
              "8   Are the anticipated career peaks of highly pro...   \n",
              "9   Is attempting to improve your batting average ...   \n",
              "10  What factors should be considered when making ...   \n",
              "11  How can one gain exposure to professionals in ...   \n",
              "12  What is the advantage of modern email clients ...   \n",
              "13  What are common paths for venture-backed entre...   \n",
              "14  How do previous conclusions, loyalties, reputa...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   The significance of the concept of \"unwilled\" ...   \n",
              "1   The Liking/Loving Tendency influences an indiv...   \n",
              "2           Ambitious director- or VP-level managers.   \n",
              "3   Blogging about their point of view can help an...   \n",
              "4   Focusing on creating a large market can be mor...   \n",
              "5                         Large-scale military combat   \n",
              "6   Intelligence is considered overrated in the in...   \n",
              "7   The purpose of temporary subfolders in email o...   \n",
              "8                                             Earlier   \n",
              "9   No, attempting to improve your batting average...   \n",
              "10  Factors that should be considered when making ...   \n",
              "11  One can gain exposure to professionals in thei...   \n",
              "12                                      I don't know.   \n",
              "13  Common paths for venture-backed entrepreneurs ...   \n",
              "14  Previous conclusions, loyalties, reputational ...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [unwilled, inadvertent, and unforseeable.\\nInd...   \n",
              "1   [One very practical consequence of Liking/Lovi...   \n",
              "2   [number of new employees recruited and hired, ...   \n",
              "3   [esting things going on, about their point of ...   \n",
              "4   [competitor, be sure to take a step back and s...   \n",
              "5   [story of an enigmatic agent for the all-power...   \n",
              "6   [Especially in this industry.\\nYou will read, ...   \n",
              "7   [the normal course of your day.\\nFourth, aside...   \n",
              "8   [early, end late, and produce at above-average...   \n",
              "9   [improve one‚Äôs batting average.\\n‚Ä¢\\nIntelligen...   \n",
              "10  [order to execute its plan? E.g. a startup pla...   \n",
              "11  [get real-world working experience at companie...   \n",
              "12  [inside and feel like you‚Äôve done something.\\n...   \n",
              "13  [that employs a lot of people like Google or A...   \n",
              "14  [[T]ending to be maintained in place by the an...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0                                                 nan      1.000000   \n",
              "1   The Liking/Loving Tendency influences an indiv...      0.500000   \n",
              "2   New hires are typically conservative and chang...      0.000000   \n",
              "3   Blogging about their point of view can help an...      0.875000   \n",
              "4   Focusing on creating a large market can be mor...      1.000000   \n",
              "5   Peter Hamilton's storytelling style in his spa...      1.000000   \n",
              "6   Intelligence is considered overrated in the in...      0.500000   \n",
              "7   The purpose of temporary subfolders in email o...      0.500000   \n",
              "8                                                 nan           NaN   \n",
              "9   Yes, attempting to improve your batting averag...      0.000000   \n",
              "10  The factors that should be considered when mak...      0.666667   \n",
              "11  One can gain exposure to professionals in thei...      1.000000   \n",
              "12  The advantage of modern email clients is that ...           NaN   \n",
              "13  If you can‚Äôt get hired by a venture-backed sta...      0.750000   \n",
              "14  A quickly reached conclusion, triggered by Dou...      0.833333   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.983218        0.800000           0.583333            0.182749  \n",
              "1           0.957709        0.000000           0.333333            0.618554  \n",
              "2           0.846774        0.000000           0.000000            0.203513  \n",
              "3           0.975708        1.000000           1.000000            0.697192  \n",
              "4           0.992700        1.000000           1.000000            0.613491  \n",
              "5           0.836724        1.000000           0.916667            0.192828  \n",
              "6           1.000000        1.000000           0.333333            0.609262  \n",
              "7           1.000000        1.000000           0.333333            0.673740  \n",
              "8           0.000000        0.000000           0.916667            0.953437  \n",
              "9           1.000000        0.000000           0.500000            0.236148  \n",
              "10          0.958568        0.000000           1.000000            0.635472  \n",
              "11          0.834602        0.666667           0.916667            0.509940  \n",
              "12          0.000000        0.000000           0.000000            0.183807  \n",
              "13          1.000000        0.500000           1.000000            0.775015  \n",
              "14          0.808429        0.500000           1.000000            0.834872  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfiu_pLh3JL"
      },
      "source": [
        "## Task 2: Making Adjustments to our RAG Pipeline\n",
        "\n",
        "Now that we have established a baseline - we can see how any changes impact our pipeline's performance!\n",
        "\n",
        "Let's modify our retriever and see how that impacts our Ragas metrics!\n",
        "\n",
        "> NOTE: MultiQueryRetriever is expanded on [here](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever) but for now, the implementation is not important to our lesson!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "nKIuM336isBL"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MultiQueryRetriever\n",
        "\n",
        "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rcj3L-i_c8"
      },
      "source": [
        "We'll also re-create our RAG pipeline using the abstractions that come packaged with LangChain v0.1.0!\n",
        "\n",
        "First, let's create a chain to \"stuff\" our documents into our context!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "EfdCgTw7jC4i"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYl5WdPnvLu"
      },
      "source": [
        "Next, we'll create the retrieval chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9AK7wHVnn0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "cmKORMfMoCjL"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Who is Taylor Swift feuding with?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICMsUWbWoOpf",
        "outputId": "1c2a8c65-0da8-44ef-d6e4-79dcca738777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but there is no information provided in the context about Taylor Swift or any feuds she may be involved in.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "5s8ZGasYoVi6"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Why are they feuding?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNCdW4hoYT8",
        "outputId": "40860a4e-75fb-486e-b1e6-34a7eb2c5295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There is no specific mention of a feud in the provided context.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxkU0HdpoaiE"
      },
      "source": [
        "Well, just from those responses this chain *feels* better - but lets see how it performs on our eval!\n",
        "\n",
        "Let's do the same process we did before to collect our pipeline's contexts and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "kO8cWxn2oinT"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgagfhPUtM2j"
      },
      "source": [
        "Now we can convert this into a dataset, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "5FcllGeSovP8"
      },
      "outputs": [],
      "source": [
        "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELYabwktR2C"
      },
      "source": [
        "Let's evaluate on the same metrics we did for the first pipeline and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "831b4dab6ff94d239d2824d390e01308",
            "4cefefc6cf714a68924e1b8d5e59aba9",
            "fd7f5542a22d44388dda12ca19443a1f",
            "93bf9b194c04460abffa192c19bcf67b",
            "83985f58744a46cfbd001ce5957f3e4a",
            "5c2b92989d7448e9bf65306c4f2f7d93",
            "a34b3906cd514234a115c7bf6757ca9d",
            "a03fefb9fa5a40ff947dc4ccd3c80318",
            "40343486e3ea4e5fae55b5a528f139d8",
            "cee2268aa21643e6ad77117c67ec1600",
            "c79f28da88f44d69aa87905c089df333"
          ]
        },
        "id": "d7uHseWJo2TU",
        "outputId": "8facfba9-467a-4129-b381-ddbd0a952f28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [02:58<00:00,  2.38s/it]\n"
          ]
        }
      ],
      "source": [
        "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JsFd0uDd2n5E",
        "outputId": "0922ab45-c16a-48c4-c9c2-3647ff130391"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of the concept of \"un...</td>\n",
              "      <td>In the context provided, the concept of \"unwil...</td>\n",
              "      <td>[unwilled, inadvertent, and unforseeable.\\nInd...</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.926343</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.179882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the Liking/Loving Tendency influence ...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>[One very practical consequence of Liking/Lovi...</td>\n",
              "      <td>The Liking/Loving Tendency influences an indiv...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.945289</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.493372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What type of employees are typically hired as ...</td>\n",
              "      <td>The context does not specify a particular type...</td>\n",
              "      <td>[How to hire the best people you've\\never work...</td>\n",
              "      <td>New hires are typically conservative and chang...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.209091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can blogging about their point of view hel...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>[esting things going on, about their point of ...</td>\n",
              "      <td>Blogging about their point of view can help an...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.975714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.655896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can focusing on creating a large market be...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>[product families or grow market share. This o...</td>\n",
              "      <td>Focusing on creating a large market can be mor...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.975897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.387932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is a key feature of Peter Hamilton's stor...</td>\n",
              "      <td>A key feature of Peter Hamilton's storytelling...</td>\n",
              "      <td>[story of an enigmatic agent for the all-power...</td>\n",
              "      <td>Peter Hamilton's storytelling style in his spa...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.841141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is intelligence considered overrated in th...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>[Especially in this industry.\\nYou will read, ...</td>\n",
              "      <td>Intelligence is considered overrated in the in...</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.872869</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.557292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of temporary subfolders in...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>[matter, right now.\\nThose subfolders then get...</td>\n",
              "      <td>The purpose of temporary subfolders in email o...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.490008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Are the anticipated career peaks of highly pro...</td>\n",
              "      <td>The anticipated career peaks of highly product...</td>\n",
              "      <td>[creator‚Äôs most distinguished work will appear...</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.185286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Is attempting to improve your batting average ...</td>\n",
              "      <td>No, attempting to improve your batting average...</td>\n",
              "      <td>[improve one‚Äôs batting average.\\n‚Ä¢\\nIntelligen...</td>\n",
              "      <td>Yes, attempting to improve your batting averag...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.228139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What factors should be considered when making ...</td>\n",
              "      <td>When making executive hires in startups, it is...</td>\n",
              "      <td>[order to execute its plan? E.g. a startup pla...</td>\n",
              "      <td>The factors that should be considered when mak...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.958568</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.425849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How can one gain exposure to professionals in ...</td>\n",
              "      <td>One way to gain exposure to professionals in y...</td>\n",
              "      <td>[get real-world working experience at companie...</td>\n",
              "      <td>One can gain exposure to professionals in thei...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834716</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.707264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is the advantage of modern email clients ...</td>\n",
              "      <td>Modern email clients can help users prioritize...</td>\n",
              "      <td>[inside and feel like you‚Äôve done something.\\n...</td>\n",
              "      <td>The advantage of modern email clients is that ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.951085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.390629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are common paths for venture-backed entre...</td>\n",
              "      <td>A common path for venture-backed entrepreneurs...</td>\n",
              "      <td>[that employs a lot of people like Google or A...</td>\n",
              "      <td>If you can‚Äôt get hired by a venture-backed sta...</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.948353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.573607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How do previous conclusions, loyalties, reputa...</td>\n",
              "      <td>Previous conclusions, loyalties, reputational ...</td>\n",
              "      <td>[[T]ending to be maintained in place by the an...</td>\n",
              "      <td>A quickly reached conclusion, triggered by Dou...</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.913534</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.720221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the significance of the concept of \"un...   \n",
              "1   How does the Liking/Loving Tendency influence ...   \n",
              "2   What type of employees are typically hired as ...   \n",
              "3   How can blogging about their point of view hel...   \n",
              "4   How can focusing on creating a large market be...   \n",
              "5   What is a key feature of Peter Hamilton's stor...   \n",
              "6   Why is intelligence considered overrated in th...   \n",
              "7   What is the purpose of temporary subfolders in...   \n",
              "8   Are the anticipated career peaks of highly pro...   \n",
              "9   Is attempting to improve your batting average ...   \n",
              "10  What factors should be considered when making ...   \n",
              "11  How can one gain exposure to professionals in ...   \n",
              "12  What is the advantage of modern email clients ...   \n",
              "13  What are common paths for venture-backed entre...   \n",
              "14  How do previous conclusions, loyalties, reputa...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   In the context provided, the concept of \"unwil...   \n",
              "1   The Liking/Loving Tendency influences an indiv...   \n",
              "2   The context does not specify a particular type...   \n",
              "3   Blogging about their point of view can help an...   \n",
              "4   Focusing on creating a large market can be mor...   \n",
              "5   A key feature of Peter Hamilton's storytelling...   \n",
              "6   Intelligence is considered overrated in the in...   \n",
              "7   The purpose of temporary subfolders in email o...   \n",
              "8   The anticipated career peaks of highly product...   \n",
              "9   No, attempting to improve your batting average...   \n",
              "10  When making executive hires in startups, it is...   \n",
              "11  One way to gain exposure to professionals in y...   \n",
              "12  Modern email clients can help users prioritize...   \n",
              "13  A common path for venture-backed entrepreneurs...   \n",
              "14  Previous conclusions, loyalties, reputational ...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [unwilled, inadvertent, and unforseeable.\\nInd...   \n",
              "1   [One very practical consequence of Liking/Lovi...   \n",
              "2   [How to hire the best people you've\\never work...   \n",
              "3   [esting things going on, about their point of ...   \n",
              "4   [product families or grow market share. This o...   \n",
              "5   [story of an enigmatic agent for the all-power...   \n",
              "6   [Especially in this industry.\\nYou will read, ...   \n",
              "7   [matter, right now.\\nThose subfolders then get...   \n",
              "8   [creator‚Äôs most distinguished work will appear...   \n",
              "9   [improve one‚Äôs batting average.\\n‚Ä¢\\nIntelligen...   \n",
              "10  [order to execute its plan? E.g. a startup pla...   \n",
              "11  [get real-world working experience at companie...   \n",
              "12  [inside and feel like you‚Äôve done something.\\n...   \n",
              "13  [that employs a lot of people like Google or A...   \n",
              "14  [[T]ending to be maintained in place by the an...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0                                                 nan      1.000000   \n",
              "1   The Liking/Loving Tendency influences an indiv...      0.000000   \n",
              "2   New hires are typically conservative and chang...      1.000000   \n",
              "3   Blogging about their point of view can help an...      1.000000   \n",
              "4   Focusing on creating a large market can be mor...      1.000000   \n",
              "5   Peter Hamilton's storytelling style in his spa...      1.000000   \n",
              "6   Intelligence is considered overrated in the in...      0.600000   \n",
              "7   The purpose of temporary subfolders in email o...      0.666667   \n",
              "8                                                 nan      1.000000   \n",
              "9   Yes, attempting to improve your batting averag...      0.333333   \n",
              "10  The factors that should be considered when mak...      0.500000   \n",
              "11  One can gain exposure to professionals in thei...      1.000000   \n",
              "12  The advantage of modern email clients is that ...      0.000000   \n",
              "13  If you can‚Äôt get hired by a venture-backed sta...      0.857143   \n",
              "14  A quickly reached conclusion, triggered by Dou...      0.454545   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.926343        1.000000           0.366667            0.179882  \n",
              "1           0.945289        1.000000           0.333333            0.493372  \n",
              "2           0.000000        0.000000           0.000000            0.209091  \n",
              "3           0.975714        1.000000           1.000000            0.655896  \n",
              "4           0.975897        0.000000           1.000000            0.387932  \n",
              "5           1.000000        0.666667           0.805556            0.841141  \n",
              "6           0.872869        1.000000           0.333333            0.557292  \n",
              "7           1.000000        1.000000           0.250000            0.490008  \n",
              "8           0.000000        0.000000           0.833333            0.185286  \n",
              "9           1.000000        1.000000           0.500000            0.228139  \n",
              "10          0.958568        0.333333           1.000000            0.425849  \n",
              "11          0.834716        0.666667           1.000000            0.707264  \n",
              "12          0.951085        0.000000           0.000000            0.390629  \n",
              "13          0.948353        0.000000           0.804167            0.573607  \n",
              "14          0.913534        1.000000           1.000000            0.720221  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results_df = advanced_retrieval_results.to_pandas()\n",
        "advanced_retrieval_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hzqq5VtZ2a"
      },
      "source": [
        "## Task 3: Evaluating our Adjusted Pipeline Against Our Baseline\n",
        "\n",
        "Now we can compare our results and see what directional changes occured!\n",
        "\n",
        "Let's refresh with our initial metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWGRaF5qx3V",
        "outputId": "7924b9a5-1bfc-4d26-f1f7-75e10fb64857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.6635, 'answer_relevancy': 0.8130, 'context_recall': 0.4978, 'context_precision': 0.6556, 'answer_correctness': 0.5280}"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFv_yAeotmFs"
      },
      "source": [
        "And see how our advanced retrieval modified our chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpV11dxJo7xa",
        "outputId": "2ce6e4b7-f037-4fd4-ca0c-1d47ff5dc522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.6941, 'answer_relevancy': 0.8202, 'context_recall': 0.5778, 'context_precision': 0.6151, 'answer_correctness': 0.4697}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62NYn3iAvTjM",
        "outputId": "732eec56-d4ef-4403-cc90-62d0c81c37cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.663462</td>\n",
              "      <td>0.694113</td>\n",
              "      <td>0.030651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.812962</td>\n",
              "      <td>0.820158</td>\n",
              "      <td>0.007196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.497778</td>\n",
              "      <td>0.577778</td>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.615093</td>\n",
              "      <td>-0.040463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.528001</td>\n",
              "      <td>0.469707</td>\n",
              "      <td>-0.058294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.663462                                    0.694113   \n",
              "1    answer_relevancy  0.812962                                    0.820158   \n",
              "2      context_recall  0.497778                                    0.577778   \n",
              "3   context_precision  0.655556                                    0.615093   \n",
              "4  answer_correctness  0.528001                                    0.469707   \n",
              "\n",
              "      Delta  \n",
              "0  0.030651  \n",
              "1  0.007196  \n",
              "2  0.080000  \n",
              "3 -0.040463  \n",
              "4 -0.058294  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task 4: Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "####üèóÔ∏è Activity #2:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "# Init OpenAI text-embedding-3-small model\n",
        "new_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-JPe1_Jx6Rnw"
      },
      "outputs": [],
      "source": [
        "# Create a in memory Qdrant vector store\n",
        "vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    new_embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs - TE3 - MQR\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "# Get a retriever for the vector store\n",
        "new_retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "M6Tyc3ZY7Km2"
      },
      "outputs": [],
      "source": [
        "# Create an advanced retriever using MQR\n",
        "new_advanced_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "# Create a retrieval chain using the new advanced retriever and existing document chain\n",
        "new_retrieval_chain = create_retrieval_chain(new_advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [],
      "source": [
        "# Collect answers of all test_questions from the improved chain that uses TE3 + MQR\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "# Make a dataset from the collected answers and contexts for evaluation\n",
        "new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "399f6ec046c34c26818a07c5efc6845a",
            "7f82e0a3c3684460b8dda773d283b535",
            "cfa01f60b62f4a88806d85cee5ac0fa6",
            "38988d3f6f5f4de3b3d4be7fec89c3c7",
            "87bd0ad74d4345dea4b409d64524f6e7",
            "8cb506949697432db061878397d196f1",
            "e7831a581d024e3ebb4026a89ceef127",
            "18701fc64eb44d26b8aa1ae0af64d09f",
            "a6581091161c489d877c2cfec432f6ae",
            "42dcc945d1624f69b63bed2fa52cc4fa",
            "5524289f1e594a5eac60ee29d9f4249c"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "6760b49b-4576-4bee-e61a-293df24e2bc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [03:05<00:00,  2.47s/it]\n"
          ]
        }
      ],
      "source": [
        "from ragas.run_config import RunConfig\n",
        "\n",
        "# Evaluate the response data based on the earlier defined metrics. run_config is provided with 5 workers (15 default) to help circumvent TPM rate limit of gpt-3.5-turbo\n",
        "new_advanced_retrieval_results = evaluate(new_response_dataset_advanced_retrieval, metrics, run_config=RunConfig(max_workers=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "53a4f4ef-13ce-4a89-a06e-6c255ed3c025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8017, 'answer_relevancy': 0.8873, 'context_recall': 0.6444, 'context_precision': 0.6695, 'answer_correctness': 0.5337}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "c496266c-bf4a-4a3a-cd27-1d8abbf5bdb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA + Baseline</th>\n",
              "      <th>ADA + MQR</th>\n",
              "      <th>TE3 + MQR</th>\n",
              "      <th>ADA + MQR -&gt; TE3 + MQR</th>\n",
              "      <th>Baseline -&gt; TE3 + MQR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.663462</td>\n",
              "      <td>0.694113</td>\n",
              "      <td>0.801667</td>\n",
              "      <td>0.107554</td>\n",
              "      <td>0.138205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.812962</td>\n",
              "      <td>0.820158</td>\n",
              "      <td>0.887328</td>\n",
              "      <td>0.067171</td>\n",
              "      <td>0.074366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.497778</td>\n",
              "      <td>0.577778</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.146667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.615093</td>\n",
              "      <td>0.669511</td>\n",
              "      <td>0.054418</td>\n",
              "      <td>0.013955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.528001</td>\n",
              "      <td>0.469707</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.064000</td>\n",
              "      <td>0.005706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  ADA + Baseline  ADA + MQR  TE3 + MQR  \\\n",
              "0        faithfulness        0.663462   0.694113   0.801667   \n",
              "1    answer_relevancy        0.812962   0.820158   0.887328   \n",
              "2      context_recall        0.497778   0.577778   0.644444   \n",
              "3   context_precision        0.655556   0.615093   0.669511   \n",
              "4  answer_correctness        0.528001   0.469707   0.533708   \n",
              "\n",
              "   ADA + MQR -> TE3 + MQR  Baseline -> TE3 + MQR  \n",
              "0                0.107554               0.138205  \n",
              "1                0.067171               0.074366  \n",
              "2                0.066667               0.146667  \n",
              "3                0.054418               0.013955  \n",
              "4                0.064000               0.005706  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'ADA + Baseline'])\n",
        "df_original = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'ADA + MQR'])\n",
        "df_comparison = pd.DataFrame(list(new_advanced_retrieval_results.items()), columns=['Metric', 'TE3 + MQR'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['ADA + MQR -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + MQR']\n",
        "df_merged['Baseline -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "####‚ùì Question #4:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?\n",
        "\n",
        "Answer:  \n",
        "Yes. All metrics have positively improved with `text-embedding-3-small` (TE3 + MQR) compared to `ada` (ADA + MQR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOciJLABDBnA"
      },
      "source": [
        "## BONUS ACTIVITY: Using a Better Generator\n",
        "\n",
        "Now that we've seen how much more effective a better Retrieval pipeline is, let's look at what impact a better(?) Generator is!\n",
        "\n",
        "Adapt the above `TE3 + MQR` pipeline to use `GPT-4o` and compare the results below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "MY8l2EksDH43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [03:55<00:00,  3.14s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.7593, 'answer_relevancy': 0.8751, 'context_recall': 0.6000, 'context_precision': 0.5880, 'answer_correctness': 0.5628}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "latest_qa_llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "latest_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=latest_qa_llm)\n",
        "\n",
        "latest_retrieval_chain = create_retrieval_chain(latest_retriever, document_chain)\n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = latest_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "latest_response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})\n",
        "\n",
        "latest_results = evaluate(latest_response_dataset, metrics, run_config=RunConfig(max_workers=5))\n",
        "\n",
        "latest_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA + Baseline</th>\n",
              "      <th>ADA + MQR</th>\n",
              "      <th>TE3 + MQR</th>\n",
              "      <th>ADA + MQR -&gt; TE3 + MQR</th>\n",
              "      <th>Baseline -&gt; TE3 + MQR</th>\n",
              "      <th>GPT4o + TE3 + MQR</th>\n",
              "      <th>TE3 + MQR -&gt; GPT4o + TE3 + MQR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.663462</td>\n",
              "      <td>0.694113</td>\n",
              "      <td>0.801667</td>\n",
              "      <td>0.107554</td>\n",
              "      <td>0.138205</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>-0.042407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.812962</td>\n",
              "      <td>0.820158</td>\n",
              "      <td>0.887328</td>\n",
              "      <td>0.067171</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.875060</td>\n",
              "      <td>-0.012268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.497778</td>\n",
              "      <td>0.577778</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>-0.044444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.615093</td>\n",
              "      <td>0.669511</td>\n",
              "      <td>0.054418</td>\n",
              "      <td>0.013955</td>\n",
              "      <td>0.587955</td>\n",
              "      <td>-0.081556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.528001</td>\n",
              "      <td>0.469707</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.064000</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.562839</td>\n",
              "      <td>0.029131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  ADA + Baseline  ADA + MQR  TE3 + MQR  \\\n",
              "0        faithfulness        0.663462   0.694113   0.801667   \n",
              "1    answer_relevancy        0.812962   0.820158   0.887328   \n",
              "2      context_recall        0.497778   0.577778   0.644444   \n",
              "3   context_precision        0.655556   0.615093   0.669511   \n",
              "4  answer_correctness        0.528001   0.469707   0.533708   \n",
              "\n",
              "   ADA + MQR -> TE3 + MQR  Baseline -> TE3 + MQR  GPT4o + TE3 + MQR  \\\n",
              "0                0.107554               0.138205           0.759259   \n",
              "1                0.067171               0.074366           0.875060   \n",
              "2                0.066667               0.146667           0.600000   \n",
              "3                0.054418               0.013955           0.587955   \n",
              "4                0.064000               0.005706           0.562839   \n",
              "\n",
              "   TE3 + MQR -> GPT4o + TE3 + MQR  \n",
              "0                       -0.042407  \n",
              "1                       -0.012268  \n",
              "2                       -0.044444  \n",
              "3                       -0.081556  \n",
              "4                        0.029131  "
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_latest = pd.DataFrame(list(latest_results.items()), columns=['Metric', 'GPT4o + TE3 + MQR'])\n",
        "\n",
        "df_merged = pd.merge(df_merged, df_latest, on=\"Metric\")\n",
        "\n",
        "df_merged['TE3 + MQR -> GPT4o + TE3 + MQR'] = df_merged['GPT4o + TE3 + MQR'] - df_merged['TE3 + MQR']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hypothesis**\n",
        "\n",
        "As the ground truths were generated using an older model `gpt-3.5-turbo-16k` and `gpt-4o`'s suspectedly better answers may have scored lower in the RAGAS evaluation metrics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05390d20f1b445b5b02529ee7a99f6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589c2004f5504a239615dec8671785d0",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d3337c457f4c748ed8bf78f5a27fe8",
            "value": 100
          }
        },
        "05ab48866b5d49df9567ce9cbda5ee2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49c1ef316e404052a7c8528781db3f9a",
              "IPY_MODEL_2dcb3e2fdf164e35a27a79cfae65933a",
              "IPY_MODEL_202f4244384a4501bfc1ffa50af96a1f"
            ],
            "layout": "IPY_MODEL_d93698b0506743ff98fdb998cfb7080a"
          }
        },
        "1317f4e20e1c4574a360345b427c3e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ef10fab64c4f40a93da3d31b572016",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3b43c3f561e34d019007ac9a0125b28d",
            "value": "‚Äá1248/1248‚Äá[00:46&lt;00:00,‚Äá13.97it/s]"
          }
        },
        "18701fc64eb44d26b8aa1ae0af64d09f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19acd28bfa2e4a7a83bc42faea5de770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d43002974f24e8a8b6961cddc04ce47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb5a4b71deb406fa2f342c88b9e4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1d22c19aff4c768d643c249e425d00",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3a498872a68049329b4d206629b9b3bf",
            "value": "embedding‚Äánodes:‚Äá100%"
          }
        },
        "202f4244384a4501bfc1ffa50af96a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10a7577a99b4683a1d59a09d88f93a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_444bc7dae1aa4e098b79655428599310",
            "value": "‚Äá20/20‚Äá[01:04&lt;00:00,‚Äá10.00s/it]"
          }
        },
        "25d3337c457f4c748ed8bf78f5a27fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa53858803d4ad39113009d86dd67fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2dcb3e2fdf164e35a27a79cfae65933a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a663f8736a43bcb47ac6c5f37ec597",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6edc46811064de2b74a6a477c4a44b7",
            "value": 20
          }
        },
        "31064d2adec14238a609d3f9791c64f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32514310070a426ea247c9f1bc66b630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7520df71de40e0af5589b6aeb95171",
              "IPY_MODEL_05390d20f1b445b5b02529ee7a99f6d6",
              "IPY_MODEL_3380693903474d2585638f7e3458fcd6"
            ],
            "layout": "IPY_MODEL_1d43002974f24e8a8b6961cddc04ce47"
          }
        },
        "3380693903474d2585638f7e3458fcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31064d2adec14238a609d3f9791c64f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f482b8ce7a54c1787394fb7d90391a0",
            "value": "‚Äá100/100‚Äá[00:33&lt;00:00,‚Äá‚Äá1.55s/it]"
          }
        },
        "356b929fa8dc42538767c58dcce12217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ec9b5c847749439d7c155ac3b1ec68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a7c333d0b241169dc29ed998b2c9c4",
            "max": 1248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c8557741734e59a6099bb5fa260f6e",
            "value": 1248
          }
        },
        "38988d3f6f5f4de3b3d4be7fec89c3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dcc945d1624f69b63bed2fa52cc4fa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5524289f1e594a5eac60ee29d9f4249c",
            "value": "‚Äá100/100‚Äá[00:45&lt;00:00,‚Äá‚Äá1.68s/it]"
          }
        },
        "399f6ec046c34c26818a07c5efc6845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f82e0a3c3684460b8dda773d283b535",
              "IPY_MODEL_cfa01f60b62f4a88806d85cee5ac0fa6",
              "IPY_MODEL_38988d3f6f5f4de3b3d4be7fec89c3c7"
            ],
            "layout": "IPY_MODEL_87bd0ad74d4345dea4b409d64524f6e7"
          }
        },
        "3a498872a68049329b4d206629b9b3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b43c3f561e34d019007ac9a0125b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7520df71de40e0af5589b6aeb95171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97abe811c89c44dcacd7e39074d22546",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_87a3d4b2ed5f4f1ca895c6a1981eb847",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "40343486e3ea4e5fae55b5a528f139d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42dcc945d1624f69b63bed2fa52cc4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444bc7dae1aa4e098b79655428599310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c1ef316e404052a7c8528781db3f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19acd28bfa2e4a7a83bc42faea5de770",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_356b929fa8dc42538767c58dcce12217",
            "value": "Generating:‚Äá100%"
          }
        },
        "4cefefc6cf714a68924e1b8d5e59aba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2b92989d7448e9bf65306c4f2f7d93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a34b3906cd514234a115c7bf6757ca9d",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "4f482b8ce7a54c1787394fb7d90391a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5524289f1e594a5eac60ee29d9f4249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589c2004f5504a239615dec8671785d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2b92989d7448e9bf65306c4f2f7d93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a663f8736a43bcb47ac6c5f37ec597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1d22c19aff4c768d643c249e425d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f82e0a3c3684460b8dda773d283b535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb506949697432db061878397d196f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e7831a581d024e3ebb4026a89ceef127",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "831b4dab6ff94d239d2824d390e01308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cefefc6cf714a68924e1b8d5e59aba9",
              "IPY_MODEL_fd7f5542a22d44388dda12ca19443a1f",
              "IPY_MODEL_93bf9b194c04460abffa192c19bcf67b"
            ],
            "layout": "IPY_MODEL_83985f58744a46cfbd001ce5957f3e4a"
          }
        },
        "83985f58744a46cfbd001ce5957f3e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a3d4b2ed5f4f1ca895c6a1981eb847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87bd0ad74d4345dea4b409d64524f6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c8557741734e59a6099bb5fa260f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89a7c333d0b241169dc29ed998b2c9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb506949697432db061878397d196f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ef10fab64c4f40a93da3d31b572016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bf9b194c04460abffa192c19bcf67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee2268aa21643e6ad77117c67ec1600",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c79f28da88f44d69aa87905c089df333",
            "value": "‚Äá100/100‚Äá[00:44&lt;00:00,‚Äá‚Äá1.69s/it]"
          }
        },
        "97abe811c89c44dcacd7e39074d22546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03fefb9fa5a40ff947dc4ccd3c80318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10a7577a99b4683a1d59a09d88f93a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34b3906cd514234a115c7bf6757ca9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6581091161c489d877c2cfec432f6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c79f28da88f44d69aa87905c089df333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee2268aa21643e6ad77117c67ec1600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa01f60b62f4a88806d85cee5ac0fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18701fc64eb44d26b8aa1ae0af64d09f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6581091161c489d877c2cfec432f6ae",
            "value": 100
          }
        },
        "d93698b0506743ff98fdb998cfb7080a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6edc46811064de2b74a6a477c4a44b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7831a581d024e3ebb4026a89ceef127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f75fdd56268a4b83a7fb7e4a3b2cce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fb5a4b71deb406fa2f342c88b9e4e1d",
              "IPY_MODEL_37ec9b5c847749439d7c155ac3b1ec68",
              "IPY_MODEL_1317f4e20e1c4574a360345b427c3e8a"
            ],
            "layout": "IPY_MODEL_2aa53858803d4ad39113009d86dd67fc"
          }
        },
        "fd7f5542a22d44388dda12ca19443a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03fefb9fa5a40ff947dc4ccd3c80318",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40343486e3ea4e5fae55b5a528f139d8",
            "value": 100
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
