{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5TTdyIoo3i7"
      },
      "source": [
        "# Creating a LlamaIndex RAG Pipeline with NL2SQL and Metadata Filtering!\n",
        "\n",
        "We'll be putting together a system for querying both qualitative and quantitative data using LlamaIndex.\n",
        "\n",
        "The acitvities will be broken down as follows:\n",
        "\n",
        "- 🤝 Breakout Room #1\n",
        "  - Task 1: Load Dependencies\n",
        "  - Task 2: Set Env Variables and Set Up WandB Callback\n",
        "  - Task 3: Initialize Settings\n",
        "  - Task 4: Index Creation\n",
        "  - Task 5: Simple RAG - `QueryEngine`\n",
        "  - Task 6: Auto Rertriever Functional Tool\n",
        "- 🤝 Breakout Room #2\n",
        "  - Task 1: Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "  - Task 2: Combined RAG Pipeline\n",
        "\n",
        "Before we get started, however, a quick note on terminology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0q6syjUVt0"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msvju70DSV_8"
      },
      "source": [
        "## BOILERPLATE\n",
        "\n",
        "This is only relevant when running the code in a Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7VF57GcmSV_9"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zQBPs6zSV_9"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhEbxl3nSV_9"
      },
      "source": [
        "Let's grab our core `llama-index` library, as well as OpenAI's Python SDK.\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs to power our RAG pipelines today.\n",
        "\n",
        "> NOTE: You can safely ignore any pip errors that occur during the running of these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3oyvtl2SV_9",
        "outputId": "16ac5d58-2a4c-46ba-bf5b-c1354eed65fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.5/863.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index openai anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqTXRTrLPatl"
      },
      "source": [
        "We'll be collecting our semantic data from Wikipedia - and so will need the [Wikipedia Reader](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/readers/llama-index-readers-wikipedia)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9kXf7pPSV_-",
        "outputId": "82458114-8712-480a-d8c6-8bf7897a2814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU wikipedia llama-index-readers-wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq_rWHZEPrCO"
      },
      "source": [
        "Our vector database today will be powered by [QDrant](https://qdrant.tech/) and so we'll need that package as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMCA8HFGEPF_",
        "outputId": "48b81d6f-854b-4151-9c5b-b45bfbd04ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.56.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index-vector-stores-qdrant qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHDqna1P1NQ"
      },
      "source": [
        "Finally, we'll need to grab a few dependencies related to our quantitative data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrT8a3c0SV__",
        "outputId": "e2d2756c-ac09-46ff-f9ea-35812f290c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U sqlalchemy pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS3I4FUabE-g"
      },
      "source": [
        "We'll can use [Weights and Biases](https://docs.wandb.ai/guides/prompts) (WandB) as a visibility platform, as well as storing our index!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UcQpjG9Ovlk",
        "outputId": "627914fd-6f08-4d85-8bfb-7a8d4cae950a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "grpcio-tools 1.64.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU wandb llama-index-callbacks-wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OHSwkDySV_-",
        "outputId": "f7f84329-d284-464d-94ed-7a5e1942bc39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WandB API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"WandB API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8E447rQBjY"
      },
      "source": [
        "We'll also need to set a callback handler for WandB to ensure smooth operation of our traces!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "MoV2JINuSV_-",
        "outputId": "22e4dabd-6274-4180-dbe3-37c2b8b0212e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/chrisalexiuk/llama-index-rag-v1/runs/48js8m4z\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
          ]
        }
      ],
      "source": [
        "import llama_index\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "set_global_handler(\"wandb\", run_args={\"project\": \"llama-index-rag-v1\"})\n",
        "wandb_callback = llama_index.core.global_handler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibtguieHP6n1"
      },
      "source": [
        "## Task 2: Set Env Variables and Set Up WandB Callback\n",
        "\n",
        "Let's set our API keys for both OpenAI and WandB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IBgMTPTSV_9",
        "outputId": "86510c6f-0388-48bb-d814-97f843b3f366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTKRJ9FaA1U1"
      },
      "source": [
        "### OPTIONAL ADVANCED PATH:\n",
        "\n",
        "Instead of OpenAI - you could use Anthropic's new Claude model `Sonnet 3.5`!\n",
        "\n",
        "Let's see how the flow might be different if you wanted to use the latest and greatest from Anthropic!\n",
        "\n",
        "> NOTE: You will need an [API Key](https://www.anthropic.com/news/claude-3-5-sonnet) for `Sonnet 3.5` for the following cells to work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tIC5feHeCN53"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL ADVANCED PATH\n",
        "!pip install -qU llama-index-llms-anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEQ6oIOeCWJ4",
        "outputId": "4b4eb456-7bba-4fe7-f55b-bd3cba6df860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anthropic API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL ADVANCED PATH\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Anthropic API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yZC0Jav4CDDl"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL ADVANCED PATH\n",
        "from llama_index.llms.anthropic import Anthropic\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = Anthropic(model=\"claude-3-sonnet-20240229\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQwigweOSV_-"
      },
      "source": [
        "## Task 3: Settings\n",
        "\n",
        "LlamaIndex lets us set global settings which we can use to influence the default behaviour of our components.\n",
        "\n",
        "Let's set our LLM and our Embedding Model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6KOy21KPSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dHWYyjG7C2OA"
      },
      "outputs": [],
      "source": [
        "Settings.embedding = OpenAIEmbedding(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOdw7EQSV_-"
      },
      "source": [
        "## Task 4: `Index` Creation\n",
        "\n",
        "In order for us to perform RAG in the traditional sense - we need an `Index`.\n",
        "\n",
        "So what is an `Index`? Well - let's see how LlamaIndex defines it:\n",
        "\n",
        "> In LlamaIndex terms, an `Index` is a data structure composed of Document objects, designed to enable querying by an LLM. Your Index is designed to be complementary to your querying strategy.\n",
        "\n",
        "Okay, so we know that we have a boatload of Wikipedia content - and we know that we want to be able to query the `Index` and receive documents that are related to our query - so let's use an `Index` built on the idea of embedding-vectors.\n",
        "\n",
        "Introducing: `VectorStoreIndex`!\n",
        "\n",
        "Again, let's see how LlamaIndex defines this:\n",
        "\n",
        "> A `VectorStoreIndex` is by far the most frequent type of `Index` you'll encounter. The Vector Store Index takes your Documents and splits them up into Nodes. It then creates `vector` embeddings of the text of every node, ready to be queried by an LLM.\n",
        "\n",
        "Alright, that sounds awesome - let's make one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDEtQQWnSV_-"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We're just going to be pulling information straight from Wikipedia using the built in `WikipediaReader`.\n",
        "\n",
        "> NOTE: Setting `auto_suggest=False` ensures we run into fewer auto-correct based errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcvGuykZSV_8"
      },
      "source": [
        "### A note on terminology:\n",
        "\n",
        "You'll notice that there are quite a few similarities between LangChain and LlamaIndex. LlamaIndex can largely be thought of as an extension to LangChain, in some ways - but they moved some of the language around. Let's spend a few moments disambiguating the language.\n",
        "\n",
        "- `QueryEngine` -> `LCEL Chain`:\n",
        "  -  `QueryEngine` is just LlamaIndex's way of indicating something is an LLM \"chain\" on top of a retrieval system\n",
        "- `OpenAIAgent` vs. `Agent`:\n",
        "  - The two agents have the same fundamental pattern: Decide which of a list of tools to use to answer a user's query.\n",
        "  - `OpenAIAgent` (LlamaIndex's primary agent) does not need to rely on an agent excecutor due to the fact that it is leveraging OpenAI's [functional api](https://openai.com/blog/function-calling-and-other-api-updates) which allows the agent to interface \"directly\" with the tools instead of operating through an intermediary application process.\n",
        "\n",
        "There is, however, a much large terminological difference when it comes to discussing data.\n",
        "\n",
        "##### Nodes vs. Documents\n",
        "\n",
        "As you're aware of from the previous weeks assignments, there's an idea of `documents` in NLP which refers to text objects that exist within a corpus of documents.\n",
        "\n",
        "LlamaIndex takes this a step further and reclassifies `documents` as `nodes`. Confusingly, it refers to the `Source Document` as simply `Documents`.\n",
        "\n",
        "The `Document` -> `node` structure is, almost exactly, equivalent to the `Source Document` -> `Document` structure found in LangChain - but the new terminology comes with some clarity about different structure-indices.\n",
        "\n",
        "We won't be leveraging those structured indicies today, but we will be leveraging a \"benefit\" of the `node` structure that exists as a default in LlamaIndex, which is the ability to quickly filter nodes based on their metadata.\n",
        "\n",
        "![image](https://i.imgur.com/B1QDjs5.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OrzzrnYMSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "movie_list = [\n",
        "    \"Dune (2021 film)\",\n",
        "    \"Dune: Part Two\",\n",
        "    \"The Lord of the Rings: The Fellowship of the Ring\",\n",
        "    \"The Lord of the Rings: The Two Towers\",\n",
        "]\n",
        "\n",
        "wiki_docs = WikipediaReader().load_data(pages=movie_list, auto_suggest=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6FRQ4hfSV_-"
      },
      "source": [
        "### Initializing our `VectorStoreIndex` with QDrant\n",
        "\n",
        "QDrant is a locally hostable and open-source vector database solution.\n",
        "\n",
        "It offers powerful features like metadata filtering out of the box, and will suit our needs well today!\n",
        "\n",
        "We'll start by creating our local `:memory:` client (in-memory and not meant for production use-cases) and our collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1ut96aSEVwY",
        "outputId": "2a30fe9e-21ef-4738-c0af-d74cbb865c31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"movie_wikis\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa3mbrfGnkCk"
      },
      "source": [
        "Then we'll create our `VectorStore` and `StorageContext` which will allow us to create an empty `VectorStoreIndex` which we will be able to add nodes to later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lZ5xilm1SV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"movie_wikis\")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    [],\n",
        "    storage_context=storage_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qtzVDelSV_-"
      },
      "source": [
        "### Node Construction\n",
        "\n",
        "Now we will loop through our documents and metadata and construct nodes.\n",
        "\n",
        "We'll make sure to explicitly associate our nodes with their respective movie so we can filter by the movie title in the upcoming cells.\n",
        "\n",
        "You might be thinking to yourself - wait, we never indicated which embedding model this should use - but remember"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LP4INgSGSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "\n",
        "pipeline = IngestionPipeline(transformations=[TokenTextSplitter()])\n",
        "\n",
        "for movie, wiki_doc in zip(movie_list, wiki_docs):\n",
        "  nodes = pipeline.run(documents=[wiki_doc])\n",
        "  for node in nodes:\n",
        "      node.metadata = {\"title\" : movie}\n",
        "  index.insert_nodes(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVzC-I4UAmB"
      },
      "source": [
        "####❓ Question #1:\n",
        "\n",
        "What `metadata` fields will the nodes in our index have?\n",
        "\n",
        "> You will need to write code to find this information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mt1lhxEnUKxO"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfbon1BwSLFS"
      },
      "source": [
        "### Persisting and Loading Stored Index with Weights and Biases\n",
        "\n",
        "Now we can utilize a powerful feature of Weights and Biases - index and artifact versioning!\n",
        "\n",
        "We can persist our index to WandB to be used and loaded later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJd00J3G48_",
        "outputId": "c5358bc1-668c-4ba8-b0a7-cc2c99e5e40e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240625_202617-zuuye5cq/files/storage)... Done. 0.1s\n"
          ]
        }
      ],
      "source": [
        "wandb_callback.persist_index(index, index_name=\"movie-index-qdrant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvpHLt8UShKa"
      },
      "source": [
        "Now we can load our index from WandB, which is a truly powerful tool!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDZLmqTDHDrZ",
        "outputId": "e8a555a2-c1fc-4f64-9cfe-e3aca19eb23f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1 of 4 files downloaded...\r\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "storage_context = wandb_callback.load_storage_context(\n",
        "    artifact_url=\"chrisalexiuk/llama-index-rag/movie-index-qdrant:v0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVVW70zyapx1"
      },
      "source": [
        "####❓ Question #2:\n",
        "\n",
        "Provide a screenshot of your index version history as shown in WandB.\n",
        "\n",
        "You can find your screenshot by doing the following:\n",
        "\n",
        "![image](https://i.imgur.com/Y0AHkQI.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSHKnb0mIte"
      },
      "source": [
        "## Task 5: Simple RAG - QueryEngine\n",
        "\n",
        "Now that we're created our `VectorStoreIndex`, powered by a QDrant VectorStore, we can wrap it in a simple `QueryEngine` using the `as_query_engine()` method - which will connect a few things together for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3ipb8j6dfLcO"
      },
      "outputs": [],
      "source": [
        "simple_rag = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgJZGr5FqAME"
      },
      "source": [
        "Before we test this out - let's see what information we can find out about from our new `QueryEngine`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-3v4ntaqFmd",
        "outputId": "c23a1ac4-5119-4e3f-c0ad-1d3ad96cc244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context information is below.\n",
            "---------------------\n",
            "{context_str}\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: {query_str}\n",
            "Answer: \n",
            "\n",
            "~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "The original query is as follows: {query_str}\n",
            "We have provided an existing answer: {existing_answer}\n",
            "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
            "------------\n",
            "{context_msg}\n",
            "------------\n",
            "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
            "Refined Answer: \n",
            "\n",
            "~~~~~~~~~~~~~~~~~~\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for k, v in simple_rag.get_prompts().items():\n",
        "  print(v.get_template())\n",
        "  print(\"\\n~~~~~~~~~~~~~~~~~~\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1YoR45tnv8h"
      },
      "source": [
        "Let's see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FgpQhKobfQ7y"
      },
      "outputs": [],
      "source": [
        "response = simple_rag.query(\"Who is the evil Wizard in the story?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "654d4vdfhnVq",
        "outputId": "1876f7a0-715e-47e0-fce0-e75bcba02881"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The evil wizard in the story is Saruman the White.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rRiijvpVoQ"
      },
      "source": [
        "That makes sense!\n",
        "\n",
        "Let's ask a question that's slightly more...ambiguous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_m0H1tbLiqME"
      },
      "outputs": [],
      "source": [
        "response = simple_rag.query(\"Who are the giant beings that roam across the world?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TEh4yjQzizeV",
        "outputId": "26ded106-476a-46d8-aa57-1b25ff69d889"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The giant beings that roam across the world are the sandworms.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOb6eh8_pnaX"
      },
      "source": [
        "We can check the source nodes to see which movies we retrieved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_qyApFDpPny",
        "outputId": "72978c32-77e8-4c8d-9f18-8e17025db37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Dune (2021 film)', 'The Lord of the Rings: The Fellowship of the Ring']\n"
          ]
        }
      ],
      "source": [
        "print([x.metadata[\"title\"] for x in response.source_nodes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBEXFmPapZpg"
      },
      "source": [
        "Okay, so in this case - we've gone with \"Sandworms \" from Dune.\n",
        "\n",
        "But there's also the Ents from Lord of the Rings, and it looks like we got documents from Lord of the Rings as well.\n",
        "\n",
        "Let's see if there's a way we can use the title metadata we added to filter the results we get!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUa5sHMsSV__"
      },
      "source": [
        "## Task 6: Auto Retriever Functional Tool\n",
        "\n",
        "This tool will leverage OpenAI's functional endpoint to select the correct metadata filter and query the filtered index - only looking at nodes with the desired metadata.\n",
        "\n",
        "A simplified diagram: ![image](https://i.imgur.com/AICDPav.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2HQHY3pSV__"
      },
      "source": [
        "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
        "\n",
        "Notice that you need to include it in a text list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KoAYxbdsSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    VectorStoreInfo,\n",
        "    MetadataInfo,\n",
        "    ExactMatchFilter,\n",
        "    MetadataFilters,\n",
        ")\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from typing import List, Tuple, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "top_k = 3\n",
        "\n",
        "vector_store_info = VectorStoreInfo(\n",
        "    content_info=\"semantic information about movies\",\n",
        "    metadata_info=[MetadataInfo(\n",
        "        name=\"title\",\n",
        "        type=\"str\",\n",
        "        description='title of the movie, one of [\"Dune (2021 film)\", \"Dune: Part Two\", \"The Lord of the Rings: The Fellowship of the Ring\", \"The Lord of the Rings: The Two Towers\"]'\n",
        "        )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEjK7jcsSV__"
      },
      "source": [
        "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yixkwF8zSV__"
      },
      "outputs": [],
      "source": [
        "class AutoRetrieveModel(BaseModel):\n",
        "    query: str = Field(..., description=\"natural language query string\")\n",
        "    filter_key_list: List[str] = Field(\n",
        "        ..., description=\"List of metadata filter field names\"\n",
        "    )\n",
        "    filter_value_list: List[str] = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep6ORS3FSV__"
      },
      "source": [
        "Now we can build our function that we will use to query the functional endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y8sPThxlSV__"
      },
      "outputs": [],
      "source": [
        "def auto_retrieve_fn(\n",
        "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
        "):\n",
        "    \"\"\"Auto retrieval function.\n",
        "\n",
        "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
        "\n",
        "    \"\"\"\n",
        "    query = query or \"Query\"\n",
        "\n",
        "    exact_match_filters = [\n",
        "        ExactMatchFilter(key=k, value=v)\n",
        "        for k, v in zip(filter_key_list, filter_value_list)\n",
        "    ]\n",
        "    retriever = VectorIndexRetriever(\n",
        "        index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
        "    )\n",
        "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
        "\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4BV6oISV__"
      },
      "source": [
        "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
        "\n",
        "Source Code Here:\n",
        "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "U4lS1NqeSV__"
      },
      "outputs": [],
      "source": [
        "description = f\"\"\"\\\n",
        "Use this tool to look up non-review based information about films.\n",
        "The vector database schema is given below:\n",
        "{vector_store_info.json()}\n",
        "\"\"\"\n",
        "\n",
        "auto_retrieve_tool = FunctionTool.from_defaults(\n",
        "    fn=auto_retrieve_fn,\n",
        "    name=\"semantic-film-info\",\n",
        "    description=description,\n",
        "    fn_schema=AutoRetrieveModel\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka_CDeOHbF-J"
      },
      "source": [
        "####❓ Question #3:\n",
        "\n",
        "Is the text in the description of our `FunctionTool` important or not? Please explain your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZblimmXVSV__"
      },
      "source": [
        "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
        "\n",
        "Source Code Here:\n",
        "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W2hafCTxSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tools=[auto_retrieve_tool],\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "agent = agent_worker.as_agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBJWDBK5SV__",
        "outputId": "7aa508c8-c6ce-41f9-892a-4c8ff6d06087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Who starred in the 2021 film?\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"Who starred in the film?\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune (2021 film)\"]}\n",
            "=== Function Output ===\n",
            "The film starred Timothée Chalamet, Rebecca Ferguson, Dave Bautista, Stellan Skarsgård, Charlotte Rampling, Oscar Isaac, Zendaya, Javier Bardem, Josh Brolin, Jason Momoa, David Dastmalchian, Stephen McKinley Henderson, Chang Chen, and Benjamin Clementine.\n",
            "=== LLM Response ===\n",
            "The 2021 film \"Dune\" featured an ensemble cast including:\n",
            "\n",
            "- Timothée Chalamet\n",
            "- Rebecca Ferguson\n",
            "- Dave Bautista\n",
            "- Stellan Skarsgård\n",
            "- Charlotte Rampling\n",
            "- Oscar Isaac\n",
            "- Zendaya\n",
            "- Javier Bardem\n",
            "- Josh Brolin\n",
            "- Jason Momoa\n",
            "- David Dastmalchian\n",
            "- Stephen McKinley Henderson\n",
            "- Chang Chen\n",
            "- Benjamin Clementine\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Who starred in the 2021 film?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZzs2PyDuJGX",
        "outputId": "cfcba867-2c9a-4dc9-9b54-abd5898de0b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Who are the giant beings that roam across the world in the movies?\n",
            "=== LLM Response ===\n",
            "In the movies:\n",
            "\n",
            "- **Dune (2021 film)**: The giant beings that roam across the world are the sandworms.\n",
            "- **The Lord of the Rings: The Two Towers**: The giant beings that roam across the world are the Ents, ancient tree-like creatures who are the guardians of the forest.\n",
            "\n",
            "There is no specific information provided about giant beings that roam across the world in \"The Lord of the Rings: The Fellowship of the Ring.\"\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Who are the giant beings that roam across the world in the movies?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_GqxFCVbKch"
      },
      "source": [
        "# 🤝 Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJcJL7VXSV__"
      },
      "source": [
        "## Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "\n",
        "We'll walk through the steps of creating a natural language to SQL system in the following section.\n",
        "\n",
        "> NOTICE: This does not have parsing on the inputs or intermediary calls to ensure that users are using safe SQL queries. Use this with caution in a production environment without adding specific guardrails from either side of the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVcM0-4SV__"
      },
      "source": [
        "The next few steps should be largely straightforward, we'll want to:\n",
        "\n",
        "1. Read in our `.csv` files into `pd.DataFrame` objects\n",
        "2. Create an in-memory `sqlite` powered `sqlalchemy` engine\n",
        "3. Cast our `pd.DataFrame` objects to the SQL engine\n",
        "4. Create an `SQLDatabase` object through LlamaIndex\n",
        "5. Use that to create a `QueryEngineTool` that we can interact with through the `NLSQLTableQueryEngine`!\n",
        "\n",
        "If you get stuck, please consult the documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwWOygTqlNBh",
        "outputId": "6cc8f96e-baec-48be-d9e8-fe3c36256378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-25 20:44:22--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133391 (130K) [text/plain]\n",
            "Saving to: ‘dune1.csv.3’\n",
            "\n",
            "dune1.csv.3         100%[===================>] 130.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-06-25 20:44:22 (4.94 MB/s) - ‘dune1.csv.3’ saved [133391/133391]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD_9LPL9lTlG",
        "outputId": "1aab3c8a-1821-4286-d05e-cd1ce4082c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-25 20:44:22--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111843 (109K) [text/plain]\n",
            "Saving to: ‘dune2.csv.3’\n",
            "\n",
            "dune2.csv.3         100%[===================>] 109.22K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-06-25 20:44:23 (3.98 MB/s) - ‘dune2.csv.3’ saved [111843/111843]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWFWvEdY1inS",
        "outputId": "35c0a109-e1e4-492e-89ab-b46dd95da206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-25 20:44:23--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_fotr.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172855 (169K) [text/plain]\n",
            "Saving to: ‘lotr_fotr.csv.3’\n",
            "\n",
            "\rlotr_fotr.csv.3       0%[                    ]       0  --.-KB/s               \rlotr_fotr.csv.3     100%[===================>] 168.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-06-25 20:44:23 (5.05 MB/s) - ‘lotr_fotr.csv.3’ saved [172855/172855]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_fotr.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nto_jNmN1n-G",
        "outputId": "868cefc8-cd9a-4cc3-b9a3-01c9468db91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-25 20:44:24--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_tt.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114598 (112K) [text/plain]\n",
            "Saving to: ‘lotr_tt.csv.3’\n",
            "\n",
            "\rlotr_tt.csv.3         0%[                    ]       0  --.-KB/s               \rlotr_tt.csv.3       100%[===================>] 111.91K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-06-25 20:44:24 (4.49 MB/s) - ‘lotr_tt.csv.3’ saved [114598/114598]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_tt.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PUg-ZuTSWAC"
      },
      "source": [
        "#### Read `.csv` Into Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "52Hd8PM4SWAC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dune1 = pd.read_csv(\"./dune1.csv\")\n",
        "dune2 = pd.read_csv(\"./dune2.csv\")\n",
        "lotr_fotr = pd.read_csv(\"./lotr_fotr.csv\")\n",
        "lotr_tt = pd.read_csv(\"./lotr_tt.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPTNyqmpSWAC"
      },
      "source": [
        "#### Create SQLAlchemy engine with SQLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4lfuPKYBSWAC"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiYiSuHSWAC"
      },
      "source": [
        "#### Convert `pd.DataFrame` to SQL tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-96asUHSWAC",
        "outputId": "2ce3fbf9-b97d-43db-f624-15cd70547534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune1.to_sql(\n",
        "  \"Dune (2021 film)\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwOi1RE1SWAC",
        "outputId": "b5d8d059-8041-422f-a482-a71db08d9d91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune2.to_sql(\n",
        "  \"Dune: Part Two\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R6FTIki4Q51",
        "outputId": "70c20a04-604b-458d-dc4e-40f54d442cee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lotr_fotr.to_sql(\n",
        "  \"The Lord of the Rings: The Fellowship of the Ring\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CiP8dwV4SFZ",
        "outputId": "8cd5325e-7f85-4228-89ac-c2e6b8990ac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lotr_tt.to_sql(\n",
        "  \"The Lord of the Rings: The Two Towers\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibA9qT7SWAC"
      },
      "source": [
        "#### Construct a `SQLDatabase` index\n",
        "\n",
        "Source Code Here:\n",
        "- [`SQLDatabase`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/langchain_helpers/sql_wrapper.py#L9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yeDYpR1LSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SQLDatabase\n",
        "\n",
        "sql_database = SQLDatabase(\n",
        "    engine=engine,\n",
        "    include_tables=movie_list\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7VfZBenSWAD"
      },
      "source": [
        "#### Create the NLSQLTableQueryEngine interface for all added SQL tables\n",
        "\n",
        "Source Code Here:\n",
        "- [`NLSQLTableQueryEngine`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/indices/struct_store/sql_query.py#L75C1-L75C1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zQWSdMtrSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
        "\n",
        "sql_query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database,\n",
        "    tables=movie_list,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8WfwuTSWAD"
      },
      "source": [
        "#### Wrap It All Up in a `QueryEngineTool`\n",
        "\n",
        "You'll want to ensure you have a descriptive...description!\n",
        "\n",
        "This is what will help the LLM decide which table to use when querying!\n",
        "\n",
        "Sorce Code Here:\n",
        "\n",
        "- [`QueryEngineTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/query_engine.py#L13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sjbHnA1bQBG"
      },
      "source": [
        "####🏗️ Activity #1:\n",
        "\n",
        "Please write a Natural Language Description for the tables that we are using today.\n",
        "\n",
        "Here is an example:\n",
        "\n",
        "```\n",
        "This tool should be used to answer any and all review related inquiries by translating a natural language query into a SQL query with access to tables:\n",
        "'Dune (2021 film)' - containing info. about the first movie in the Dune series,\n",
        "'Dune: Part Two'- containing info. about about the second movie in the Dune series,\n",
        "'The Lord of the Rings: The Fellowship of the Ring' - containing info. about the first movie in the Lord of the Ring series,\n",
        "'The Lord of the Rings: The Two Towers' - containing info. the second movie in the Lord of the Ring series,\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4n567cXVVCtX"
      },
      "outputs": [],
      "source": [
        "DESCRIPTION = \"\"\"\\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "y-mmcBbLSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools.query_engine import QueryEngineTool\n",
        "\n",
        "sql_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=sql_query_engine,\n",
        "    name=\"sql-query\",\n",
        "    description=DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "feOrlq4XSWAD"
      },
      "outputs": [],
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tools=[sql_tool],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "agent = agent_worker.as_agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT4G6stBSWAD",
        "outputId": "94f8b39c-1584-4602-ed49-297e214b6aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is the average rating of the 2nd Lord of the Rings movie?\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Two Towers\\\";\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Two Towers\" is approximately 9.18.\n",
            "=== LLM Response ===\n",
            "The average rating of \"The Lord of the Rings: The Two Towers\" is approximately 9.18.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is the average rating of the 2nd Lord of the Rings movie?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhsoxOpkSWAD",
        "outputId": "84742e5b-e379-474f-e2f3-035ec9d13463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average rating of \"The Lord of the Rings: The Two Towers\" is approximately 9.18.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FiAS6sF7DoJ",
        "outputId": "d14d4382-2fe9-4092-c9fd-b19344d4f303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What movie series has better reviews, Lord of the Rings or Dune?\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Fellowship of the Ring\\\" UNION ALL SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Two Towers\\\";\"}\n",
            "=== Function Output ===\n",
            "It appears that there was an error in the SQL query provided. The error message indicates that the SQL statement is invalid. To correct this, we need to ensure that the table names and column names are correctly referenced and that the SQL syntax is accurate.\n",
            "\n",
            "Here is a corrected version of the SQL query:\n",
            "\n",
            "```sql\n",
            "SELECT AVG(rating) as average_rating FROM \"The_Lord_of_the_Rings_The_Fellowship_of_the_Ring\"\n",
            "UNION ALL\n",
            "SELECT AVG(rating) as average_rating FROM \"The_Lord_of_the_Rings_The_Two_Towers\";\n",
            "```\n",
            "\n",
            "Assuming the corrected query runs successfully, the response would provide the average ratings for both movies. However, since we don't have the actual data, we can't provide the exact average ratings. \n",
            "\n",
            "If you run the corrected query in your database, you should receive two rows of results, each containing the average rating for one of the movies. Here is an example of what the output might look like:\n",
            "\n",
            "```\n",
            "average_rating\n",
            "---------------\n",
            "8.8\n",
            "8.7\n",
            "```\n",
            "\n",
            "In this example, the average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is 8.8, and the average rating for \"The Lord of the Rings: The Two Towers\" is 8.7. Please run the corrected query in your database to get the actual average ratings.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"Dune (2021 film)\\\" UNION ALL SELECT AVG(rating) as average_rating FROM \\\"Dune: Part Two\\\";\"}\n",
            "=== Function Output ===\n",
            "It appears that there was an error in the SQL query provided. The error message indicates that the SQL statement is invalid. To correct this, we need to ensure that the SQL syntax is correct and that the table names and column names are properly referenced.\n",
            "\n",
            "Here is a corrected version of the SQL query:\n",
            "\n",
            "```sql\n",
            "SELECT AVG(rating) as average_rating FROM \"Dune (2021 film)\"\n",
            "UNION ALL\n",
            "SELECT AVG(rating) as average_rating FROM \"Dune: Part Two\";\n",
            "```\n",
            "\n",
            "Assuming the corrected query runs successfully, it would return two rows, each containing the average rating for \"Dune (2021 film)\" and \"Dune: Part Two\" respectively.\n",
            "\n",
            "If you need a synthesized response based on the expected results of the corrected query, it would look something like this:\n",
            "\n",
            "\"The average rating for 'Dune (2021 film)' is X, while the average rating for 'Dune: Part Two' is Y.\"\n",
            "\n",
            "Please replace X and Y with the actual average ratings obtained from the query results.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Fellowship of the Ring\\\";\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Two Towers\\\";\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Two Towers\" is approximately 9.18.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"Dune (2021 film)\\\";\"}\n",
            "=== Function Output ===\n",
            "The average rating for the film \"Dune (2021)\" is approximately 8.34.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"Dune: Part Two\\\";\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"Dune: Part Two\" is approximately 8.71.\n",
            "=== LLM Response ===\n",
            "Here are the average ratings for the movies in each series:\n",
            "\n",
            "**Lord of the Rings:**\n",
            "- The Fellowship of the Ring: 9.87\n",
            "- The Two Towers: 9.18\n",
            "\n",
            "**Dune:**\n",
            "- Dune (2021): 8.34\n",
            "- Dune: Part Two: 8.71\n",
            "\n",
            "Based on these average ratings, the Lord of the Rings series has better reviews compared to the Dune series.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What movie series has better reviews, Lord of the Rings or Dune?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxDA2Gjm7dDZ",
        "outputId": "41726e3c-9441-4875-ce33-7b8824684553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are the average ratings for the movies in each series:\n",
            "\n",
            "**Lord of the Rings:**\n",
            "- The Fellowship of the Ring: 9.87\n",
            "- The Two Towers: 9.18\n",
            "\n",
            "**Dune:**\n",
            "- Dune (2021): 8.34\n",
            "- Dune: Part Two: 8.71\n",
            "\n",
            "Based on these average ratings, the Lord of the Rings series has better reviews compared to the Dune series.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2LOixbcSWAD"
      },
      "source": [
        "### Task 2: Combined RAG Pipeline\n",
        "\n",
        "Now, we can simply add our tools into the `OpenAIAgent`, and off we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "uxFHM2l2SWAD"
      },
      "outputs": [],
      "source": [
        "combined_tool_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tools=[auto_retrieve_tool, sql_tool],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "combined_tool_agent = combined_tool_agent_worker.as_agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVHuBf9SWAD",
        "outputId": "870eeafe-1082-4b1d-8897-75a6fc2242e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Which movie is about a ring, and what is the average rating of the movie?\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"movie about a ring\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"The Lord of the Rings: The Fellowship of the Ring\", \"The Lord of the Rings: The Two Towers\"]}\n",
            "=== Function Output ===\n",
            "The movie is about the Dark Lord Sauron, who seeks the One Ring to return to power. The Ring has found its way to a young hobbit named Frodo Baggins. Frodo and eight companions form the Fellowship of the Ring and embark on a perilous journey to Mount Doom in Mordor, the only place where the Ring can be destroyed.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Fellowship of the Ring\\\"\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87.\n",
            "=== LLM Response ===\n",
            "The movie about a ring is \"The Lord of the Rings: The Fellowship of the Ring.\" It tells the story of the Dark Lord Sauron, who seeks the One Ring to return to power. The Ring has found its way to a young hobbit named Frodo Baggins. Frodo and eight companions form the Fellowship of the Ring and embark on a perilous journey to Mount Doom in Mordor, the only place where the Ring can be destroyed.\n",
            "\n",
            "The average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"Which movie is about a ring, and what is the average rating of the movie?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0w0VbomSWAD",
        "outputId": "cb34be55-800f-4a2b-b926-571fd57a0ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The movie about a ring is \"The Lord of the Rings: The Fellowship of the Ring.\" It tells the story of the Dark Lord Sauron, who seeks the One Ring to return to power. The Ring has found its way to a young hobbit named Frodo Baggins. Frodo and eight companions form the Fellowship of the Ring and embark on a perilous journey to Mount Doom in Mordor, the only place where the Ring can be destroyed.\n",
            "\n",
            "The average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJvN-vtJSWAD",
        "outputId": "2f832372-8f8a-4cd6-90a2-e7cb44f57e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What worlds do the LoTR, and Dune movies take place in?\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"world where the movie takes place\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"The Lord of the Rings: The Fellowship of the Ring\", \"The Lord of the Rings: The Two Towers\"]}\n",
            "=== Function Output ===\n",
            "The movie takes place in the fictional world of Middle-earth.\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"world where the movie takes place\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune (2021 film)\", \"Dune: Part Two\"]}\n",
            "=== Function Output ===\n",
            "The movie takes place in a distant future where humanity has spread across the universe and settled on various planets. The primary settings include the desert planet Arrakis, known for its valuable spice melange, the oceanic planet Caladan, and the industrial planet Giedi Prime. The story revolves around the political and social dynamics of these planets and their inhabitants.\n",
            "=== LLM Response ===\n",
            "The worlds where the movies take place are as follows:\n",
            "\n",
            "- **The Lord of the Rings: The Fellowship of the Ring** and **The Lord of the Rings: The Two Towers** take place in the fictional world of **Middle-earth**.\n",
            "\n",
            "- **Dune (2021 film)** and **Dune: Part Two** take place in a distant future where humanity has spread across the universe and settled on various planets. The primary settings include the desert planet **Arrakis**, known for its valuable spice melange, the oceanic planet **Caladan**, and the industrial planet **Giedi Prime**. The story revolves around the political and social dynamics of these planets and their inhabitants.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"What worlds do the LoTR, and Dune movies take place in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F74wGv6NSWAD",
        "outputId": "6e1ebf92-fb04-4dd0-bcf2-2e5069e07039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The worlds where the movies take place are as follows:\n",
            "\n",
            "- **The Lord of the Rings: The Fellowship of the Ring** and **The Lord of the Rings: The Two Towers** take place in the fictional world of **Middle-earth**.\n",
            "\n",
            "- **Dune (2021 film)** and **Dune: Part Two** take place in a distant future where humanity has spread across the universe and settled on various planets. The primary settings include the desert planet **Arrakis**, known for its valuable spice melange, the oceanic planet **Caladan**, and the industrial planet **Giedi Prime**. The story revolves around the political and social dynamics of these planets and their inhabitants.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvat4hmkvn3N",
        "outputId": "a9b1153d-7dcd-4f0c-af05-06b812f6574d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Which of the following movie series is considered the 'best': Dune, or Lord of the Rings? Base your answer on both reviews, and non-review information.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"Dune (2021 film)\\\"\"}\n",
            "=== Function Output ===\n",
            "The average rating for the film \"Dune (2021)\" is approximately 8.34.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"Dune: Part Two\\\"\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"Dune: Part Two\" is approximately 8.71.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Fellowship of the Ring\\\"\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87.\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) as average_rating FROM \\\"The Lord of the Rings: The Two Towers\\\"\"}\n",
            "=== Function Output ===\n",
            "The average rating for \"The Lord of the Rings: The Two Towers\" is approximately 9.18.\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"critical acclaim and awards\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune (2021 film)\", \"Dune: Part Two\", \"The Lord of the Rings: The Fellowship of the Ring\", \"The Lord of the Rings: The Two Towers\"]}\n",
            "=== Function Output ===\n",
            "The film \"Dune\" received generally positive critical acclaim, particularly for its ambition, story, scope, worldbuilding, performances (especially those of Timothée Chalamet and Rebecca Ferguson), and production values. However, some critics found the story incomplete and dull, and there were mixed opinions on the runtime, pacing, and adaptation of the source material. \n",
            "\n",
            "On Rotten Tomatoes, 83% of 514 critics' reviews were positive, with an average rating of 7.6/10. Metacritic gave the film a weighted average score of 74 out of 100, indicating \"generally favorable reviews.\" Audience responses were also positive, with CinemaScore giving it an average grade of \"A−\" and PostTrak reporting an 84% positive score and 66% of viewers saying they would definitely recommend it.\n",
            "\n",
            "The film's critical reception highlighted its worldbuilding, ensemble cast, set pieces, and production design, though some critics had reservations about its ending and the portrayal of cultural elements.\n",
            "=== LLM Response ===\n",
            "### Reviews and Ratings\n",
            "\n",
            "#### Dune Series\n",
            "- **Dune (2021 film)**\n",
            "  - Average Rating: 8.34\n",
            "  - Critical Acclaim: Generally positive, praised for ambition, story, scope, worldbuilding, performances, and production values. Some criticism for being incomplete and dull, with mixed opinions on runtime, pacing, and adaptation.\n",
            "  - Rotten Tomatoes: 83% positive reviews, average rating 7.6/10\n",
            "  - Metacritic: Score of 74/100\n",
            "  - Audience Responses: CinemaScore grade \"A−\", PostTrak 84% positive score, 66% would recommend\n",
            "\n",
            "- **Dune: Part Two**\n",
            "  - Average Rating: 8.71\n",
            "\n",
            "#### The Lord of the Rings Series\n",
            "- **The Lord of the Rings: The Fellowship of the Ring**\n",
            "  - Average Rating: 9.87\n",
            "\n",
            "- **The Lord of the Rings: The Two Towers**\n",
            "  - Average Rating: 9.18\n",
            "\n",
            "### Non-Review Information\n",
            "- **Dune Series**\n",
            "  - The Dune series is set in a distant future with humanity spread across various planets, focusing on political and social dynamics, particularly on the desert planet Arrakis.\n",
            "\n",
            "- **The Lord of the Rings Series**\n",
            "  - The Lord of the Rings series is set in the fictional world of Middle-earth, focusing on the quest to destroy the One Ring to prevent the Dark Lord Sauron from returning to power.\n",
            "\n",
            "### Conclusion\n",
            "Based on both reviews and non-review information, **The Lord of the Rings series** is considered the 'best' compared to the Dune series. The average ratings for both \"The Fellowship of the Ring\" and \"The Two Towers\" are significantly higher than those for the Dune movies. Additionally, the Lord of the Rings series has received widespread acclaim for its storytelling, worldbuilding, and overall impact on the fantasy genre.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"Which of the following movie series is considered the 'best': Dune, or Lord of the Rings? Base your answer on both reviews, and non-review information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEOpeuAovtZM",
        "outputId": "9446476b-061c-464a-ef08-25cbb6a97b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Reviews and Ratings\n",
            "\n",
            "#### Dune Series\n",
            "- **Dune (2021 film)**\n",
            "  - Average Rating: 8.34\n",
            "  - Critical Acclaim: Generally positive, praised for ambition, story, scope, worldbuilding, performances, and production values. Some criticism for being incomplete and dull, with mixed opinions on runtime, pacing, and adaptation.\n",
            "  - Rotten Tomatoes: 83% positive reviews, average rating 7.6/10\n",
            "  - Metacritic: Score of 74/100\n",
            "  - Audience Responses: CinemaScore grade \"A−\", PostTrak 84% positive score, 66% would recommend\n",
            "\n",
            "- **Dune: Part Two**\n",
            "  - Average Rating: 8.71\n",
            "\n",
            "#### The Lord of the Rings Series\n",
            "- **The Lord of the Rings: The Fellowship of the Ring**\n",
            "  - Average Rating: 9.87\n",
            "\n",
            "- **The Lord of the Rings: The Two Towers**\n",
            "  - Average Rating: 9.18\n",
            "\n",
            "### Non-Review Information\n",
            "- **Dune Series**\n",
            "  - The Dune series is set in a distant future with humanity spread across various planets, focusing on political and social dynamics, particularly on the desert planet Arrakis.\n",
            "\n",
            "- **The Lord of the Rings Series**\n",
            "  - The Lord of the Rings series is set in the fictional world of Middle-earth, focusing on the quest to destroy the One Ring to prevent the Dark Lord Sauron from returning to power.\n",
            "\n",
            "### Conclusion\n",
            "Based on both reviews and non-review information, **The Lord of the Rings series** is considered the 'best' compared to the Dune series. The average ratings for both \"The Fellowship of the Ring\" and \"The Two Towers\" are significantly higher than those for the Dune movies. Additionally, the Lord of the Rings series has received widespread acclaim for its storytelling, worldbuilding, and overall impact on the fantasy genre.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1qaiDJYb1_v"
      },
      "source": [
        "####❓ Question #4:\n",
        "\n",
        "How can you verify which tool was used for which query?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "D3ELqzOvSWAD"
      },
      "outputs": [],
      "source": [
        "wandb_callback.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
